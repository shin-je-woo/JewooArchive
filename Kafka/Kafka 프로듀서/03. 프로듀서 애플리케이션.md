# 💡 프로듀서 API 구현하기

먼저 build.gradle에 카프카 클라이언트 라이브러리를 추가한다.

```
dependencies {
    //...
    implementation 'org.apache.kafka:kafka-clients:2.5.0'
}
```

다음은 간단한 프로듀서 API 사용법이다.

```java
public class SimpleProducer {
    private static final Logger logger = LoggerFactory.getLogger(SimpleProducer.class);
    private static final String TOPIC_NAME = "test";
    private static final String BOOTSTRAP_SERVERS = "my-kafka:9092";

    public static void main(String[] args) {
        // 카프카 프로듀서 설정하기
        // 3가지 필수값은 반드시 포함해야 함. bootstrap.servers, key.serializer, value.serializer
        Properties configs = new Properties();
        configs.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, BOOTSTRAP_SERVERS);
        configs.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
        configs.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());

        try (KafkaProducer<String, String> producer = new KafkaProducer<>(configs)) {
            // 기본 전송
            ProducerRecord<String, String> record = new ProducerRecord<>(TOPIC_NAME, "jewooValue");
            producer.send(record);

            // 메시지 키를 지정하여 레코드 전송
            ProducerRecord<String, String> record2 = new ProducerRecord<>(TOPIC_NAME, "jewoo2", "jewooValue2"); // 키가 있는 레코드
            producer.send(record2);

            // 파티션을 지정하여 레코드 전송
            int partitionNo = 0;
            ProducerRecord<String, String> record = new ProducerRecord<>(TOPIC_NAME, partitionNo, "jewoos3", "jewoosValue3"); // 특정 파티션으로 전송하는 레코드
            producer.send(record);
        }
    }
}
```

- 메시지 키가 포함된 레코드를 전송하고 싶다면 ProducerRecord 생성 시 파라미터로 추가해야 한다.
- 토픽 이름, 메시지 키, 메시지 값을 순서대로 파라미터로 넣고 생성했을 경우 메시지 키가 지정된다.
- 파티션을 직접 지정하고 싶다면 토픽 이름, 파티션 번호, 메시지 키, 메시지 값을 순서대로 파라미터로 넣고 레코드를 생성하면 된다.
- 파티션 번호는 토픽에 존재하는 파티션 번호로 설정해야 한다.

# 💡 커스텀 파티셔너

- 프로듀서 사용환경에 따라 특정 데이터를 가지는 레코드를 특정 파티션으로 보내야 할 때가 있다.
- 예를 들어, jewooKey라는 키를 가진 메시지가 0번 파티션으로 들어가야 한다고 가정하자.
- 기본 설정 파티셔너를 사용할 경우 메시지 키의 해시값을 파티션에 매칭하여 데이터를 전송하므로 어느 파티션에 들어갈지 알 수 없다.
- 이 때, `Partitioner` 인터페이스를 사용하여 사용자 정의 파티셔너를 생성하면 jewooKey라는 키를 가진 메시지에 대해서 무조건 0번 파티션으로 지정하도록 설정할 수 있다.
- 이렇게 지정할 경우 토픽의 파티션 개수가 변경되더라도 jewooKey라는 키를 가진 메시지는 파티션 0번에 적재된다.

```java
public class CustomPartitioner implements Partitioner {

    @Override
    public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster) {

        if (keyBytes == null) {
            throw new InvalidRecordException("Need message key");
        }

        // key가 jewooKey일 경우 0번 파티션으로 전송
        if (key instanceof String && key.equals("jewooKey")) {
            return 0;
        }

        // 아닐 경우 해시값으로 파티션 계산
        List<PartitionInfo> partitions = cluster.partitionsForTopic(topic);
        int numPartitions = partitions.size();
        return Utils.toPositive(Utils.murmur2(keyBytes)) % numPartitions;
    }

    @Override
    public void close() {

    }

    @Override
    public void configure(Map<String, ?> configs) {

    }
}
```

```java
public class ProducerWithCustomPartitioner {
    private final static String TOPIC_NAME = "test";
    private final static String BOOTSTRAP_SERVERS = "my-kafka:9092";

    public static void main(String[] args) {
        Properties configs = new Properties();
        configs.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, BOOTSTRAP_SERVERS);
        configs.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
        configs.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
        configs.put(ProducerConfig.PARTITIONER_CLASS_CONFIG, CustomPartitioner.class.getName()); // 커스텀 파티셔너 설정

        try (KafkaProducer<String, String> producer = new KafkaProducer<>(configs)) {
            ProducerRecord<String, String> record = new ProducerRecord<>(TOPIC_NAME, "jewooKey", "jewooValue");
            producer.send(record);
        }
    }
}
```

# 💡 레코드 전송 결과 확인하기

- 지금까지 작성한 코드는 프로듀서가 브로커로 메시지를 보낸 후 성공적으로 도착했는지까지는 확인하지 않는 프로듀서의 코드이다.
- 브로커가 살아있다면 프로듀서는 메시지 전송에 실패하더라도 자동으로 재전송하기 때문에 대부분의 경우 성공적으로 전송되지만, 일부 메시지가 손실될 수도 있다.
- 따라서, 적절하게 결과를 확인하는 코드가 필요하다.

## 동기 방식

- KafkaProducer의 send() 메서드는 Future객체를 반환한다.
- 이 객체는 RecordMetadata의 비동기 결과를 표현하는 것으로 ProducerRecord가 카프카 브로커에 정상적으로 적재되었는지에 대한 데이터가 포함되어 있다.
- 다음 코드와 같이 get() 메서드를 사용하면 프로듀서로 보낸 데이터의 결과를 동기적으로 가져올 수 있다.

```java
public class ProducerWithSyncCallback {
    private final static Logger logger = LoggerFactory.getLogger(ProducerWithSyncCallback.class);
    private final static String TOPIC_NAME = "test";
    private final static String BOOTSTRAP_SERVERS = "my-kafka:9092";

    public static void main(String[] args) {
        Properties configs = new Properties();
        configs.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, BOOTSTRAP_SERVERS);
        configs.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
        configs.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());

        try (KafkaProducer<String, String> producer = new KafkaProducer<>(configs)) {
            ProducerRecord<String, String> record = new ProducerRecord<>(TOPIC_NAME, "jewoo", "jewoosValue");
            Future<RecordMetadata> future = producer.send(record);
            RecordMetadata metadata = future.get(); // 동기적으로 결과 확인하기
            logger.info("Partition={}, Offset={}", metadata.partition(), metadata.offset());
        } catch (Exception e) {
            logger.error(e.getMessage(), e);
        }
    }
}
```

![image](https://github.com/user-attachments/assets/c46b2f35-bbda-4cab-96d0-b1955d723c4c)

## 비동기 방식

- 앞의 동기 방식으로 결과를 확인 할 경우, 프로듀서가 보낸 모든 메시지에 대해 응답을 기다리며 스레드들이 정지한다면 효율성이 떨어지게 된다.
- 하지만 비동기적으로 결과를 확인하게 된다면 응답을 기다리지 않고 바로 다음 일을 수행할 수 있기 때문에 더욱 효율적이다.
- 아래의 코드에서 프로듀서는 send() 메서드에 콜백과 같이 호출하고 카프카 브로커에서 응답을 받으면 콜백된다.

```java
//...
import org.apache.kafka.clients.producer.Callback;

public class ProducerCallback implements Callback {
    private final static Logger logger = LoggerFactory.getLogger(ProducerCallback.class);

    @Override
    public void onCompletion(RecordMetadata metadata, Exception exception) {
        if (exception != null) {
            logger.error(exception.getMessage(), exception);
        } else {
            logger.info("Partition={}, Offset={}", metadata.partition(), metadata.offset());
        }
    }
}
```

```java
public class ProducerWithAsyncCallback {
    private final static String TOPIC_NAME = "test";
    private final static String BOOTSTRAP_SERVERS = "my-kafka:9092";

    public static void main(String[] args) {
        Properties configs = new Properties();
        configs.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, BOOTSTRAP_SERVERS);
        configs.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
        configs.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());

        try (KafkaProducer<String, String> producer = new KafkaProducer<>(configs)) {
            ProducerRecord<String, String> record = new ProducerRecord<>(TOPIC_NAME, "jewoo", "jewooValue");
            producer.send(record, new ProducerCallback()); // send()에 Callback 지정하기
        }
    }
}
```

![image](https://github.com/user-attachments/assets/92d4bc4a-365b-482c-96af-7b100789a69a)

- 실행 결과를 보면 동기방식과 다르게 main스레드가 아닌 특별한 스레드에서 콜백이 수행된 것을 확인할 수 있다.
- 예제에서는 예외 처리를 단순하게 로그를 출력했지만, 실제 운영환경에서는 적절하게 예외처리가 필요하다.
