# 💡 토픽과 파티션

![image](https://github.com/user-attachments/assets/062a61a3-42b3-4750-9674-99a1a9cfae96)

- 토픽은 카프카에서 데이터를 구분하기 위해 사용하는 단위이다.
- 토픽은 1개 이상의 파티션을 소유하고 있다.
- 파티션에는 프로듀서가 보낸 데이터들이 저장되는데, 이 데이터를 ‘레코드(record)’라고 부른다.
- 파티션은 자료구조에서 접하는 큐(queue)와 비슷한 구조라고 생각하면 쉽다.
- First-in-first-out(FIFO) 구조와 같이 먼저 들어간 레코드는 컨슈머가 먼저 가져가게 된다.
- 다만, 일반적인 자료구조로 사용되는 큐는 데이터를 가져가면(pop) 삭제하지만, 카프카에서는 삭제하지 않는다.
- 파티션의 레코드는 컨슈머가 가져가는 것과 별개로 관리된다. 이러한 특징 때문에 토픽의 레코드는 다양한 목적을 가진 여러 컨슈머 그룹들이 토픽의 데이터를 여러번 가져갈 수 있다.

# 💡 토픽 생성 시 파티션이 배치되는 방법

![image](https://github.com/user-attachments/assets/82d3e4cb-4431-4207-addd-f49efe026e1b)

- 파티션이 5개인 토픽을 생성했을 경우 그림과 같이 0번 브로커부터 시작하여 round-robin 방식으로 리더 파티션들이 생성된다.
- 카프카 클라이언트는 리더 파티션이 있는 브로커와 통신하여 데이터를 주고 받으므로 여러 브로커에 골고루 네트워크 통신을 하게 된다.
- 이를 통해, 데이터가 특정 서버(여기서는 브로커)와 통신이 집중되는(hot spot) 현상을 막고 선형 확장(linear scale out)을 하여 데이터가 많아지더라도 자연스럽게 대응할 수 있게 된다.

![image](https://github.com/user-attachments/assets/ccb30c9e-bece-486f-8492-cc6e26cee4fa)

# 💡 특정 브로커에 파티션이 쏠린 현상

![image](https://github.com/user-attachments/assets/741aeb2d-4613-4694-bcd2-003ab9d431a5)

- 특정 브로커에 파티션이 몰린 경우 `kafka-reassign-partitions.sh` 명령으로 파티션을 재분배할 수 있다.

# 💡 파티션 개수와 컨슈머 개수의 처리량

![image](https://github.com/user-attachments/assets/454ef118-d164-4d48-a0b9-dff1e242cfc7)

- 파티션은 카프카의 병렬처리의 핵심으로써 그룹으로 묶인 컨슈머들이 레코드를 병렬로 처리할 수 있도록 매칭된다.
- 컨슈머의 처리량이 한정된 상황에서 많은 레코드를 병렬로 처리하는 가장 좋은 방법은 컨슈머의 개수를 늘려 스케일 아웃하는 것이다.
- 컨슈머 개수를 늘림과 동시에 파티션 개수도 늘리면 처리량이 증가 하는 효과를 볼 수있다.

# 💡 파티션 개수를 줄이는 것은 불가능

![image](https://github.com/user-attachments/assets/42fea6a7-194f-4edf-8b82-6fe2af6b20b4)

- 카프카에서 파티션 개수를 줄이는 것은 지원하지 않는다.
- 그러므로 파티션을 늘리는 작업을 할 때는 신중히 파티션 개수를 정해야 한다.
- 한번 늘리면 줄이는 것은 불가능하기 때문에 토픽을 삭제하고 재생성하는 방법 외에는 없기 때문이다.
- 카프카에서는 파티션의 데이터를 세그먼트로 저장하고 있으며 만에 하나 지원을 한다고 하더라도 여러 브로커에 저장된 데이터를 취합하고 정렬 해야 하는 복잡한 과정을 거쳐야 하기 때문에 클러스터에 큰 영향이 가게 된다.
