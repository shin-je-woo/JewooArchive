# Previous
카프카로 이벤트를 처리하다 보면 다음과 같은 고민을 해볼 수 있을 것 같다.

발행된 이벤트를 순서대로 처리해야 한다면?

예를 들어, 고객 요청 순서대로 알림을 발송한다던가, 로그 순서대로 DB에 적재한다던가 하는 상황을 생각해볼 수 있다.

보통 카프카를 사용할 때 병렬처리를 위해 파티션을 여러개로 구성하고, 매칭되는 컨슈머를 만들어 처리하게 된다.

이럴 경우 이벤트 처리 순서가 보장될 수 없다.

# 💡 어떻게 처리순서를 보장할까? (고민)

해결방법으로 가장 먼저 생각나는 것은 토픽의 (리더)파티션을 1개만 생성하거나, 파티셔너를 커스텀하여 하나의 파티션으로만 데이터가 적재되도록 하는 방법이다.

그러면 파티션에 이벤트 발행 순서대로 이벤트가 적재될 것이고, 컨슈머도 1개이므로 차례대로 처리됨이 보장된다.

다만, 이 경우에 처리량이 낮아질 수 밖에 없다. 

여러 개의 컨슈머로 수행하던 작업을 '순서대로'라는 요구사항 때문에 처리량이 줄어드는 현상이 발생하게 된다.

두 번째로 생각나는 방법은 Redis에 요청순서대로 데이터를 적재하고, 여러개의 컨슈머에서 Redis의 데이터를 차례대로 가져가서 처리하는 방법이다.

이 방법은 Redis라는 외부 시스템과의 통신이 발생하기도 하고, Redis에 데이터를 적재하고 가져가는 과정에서 프로듀서와 컨슈머 모두 약간의 Delay가 발생할 수 있다.

이 방법은 추가적인 Network I/O, Delay관련 처리량 감소와 싱글 컨슈머 방식과의 Trade-off를 잘 고려해봐야 할 것같다.
